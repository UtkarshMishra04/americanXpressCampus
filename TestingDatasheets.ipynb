{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#Reading data\n",
    "\n",
    "df_training = pd.read_csv(\"Training_dataset_Original.csv\")\n",
    "df_eval = pd.read_csv(\"Evaluation_dataset.csv\")\n",
    "df_leader = pd.read_csv(\"Leaderboard_dataset.csv\")\n",
    "df_datadict = pd.read_csv(\"Data_Dictionary.csv\")\n",
    "\n",
    "df_training = df_training.drop(['application_key'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mvar1   mvar2   mvar3  mvar4  mvar5    mvar6    mvar7    mvar8    mvar9  \\\n",
      "0      1696  1.6541   0.000  0.000  0.000        0     6015      322    40369   \n",
      "1      1846  0.8095   0.000  0.000  0.000      102     7532     3171    18234   \n",
      "2      1745  0.4001   0.000  0.000  0.000  missing     2536  missing  missing   \n",
      "3      1739  0.2193   0.000  0.000  0.000     1982    26440     4955    20316   \n",
      "4      1787  0.0118   0.225  0.000  0.000     5451     5494     5494     7987   \n",
      "5      1579     NaN   3.502  0.000  0.000  missing  missing  missing  missing   \n",
      "6      1818  0.4001   0.000  0.000  0.000  missing     1088  missing     1536   \n",
      "7        na     NaN     NaN    NaN    NaN  missing  missing  missing  missing   \n",
      "8      1836  0.1358   0.000  0.000  0.000      347    38964    17828    70729   \n",
      "9      1839  0.1981   0.000  0.000  0.000      793     6131     6045    48959   \n",
      "10     1903  0.0000   0.000  0.000  0.000       22    19518     9910    90618   \n",
      "11     1681  1.5888   5.685  3.566  0.000       93     3554      439     2527   \n",
      "12     1841  0.5388   0.000  0.000  0.000     1487    19449    19449     6739   \n",
      "13     1794  1.9684   0.000  0.000  0.000      856     8609     8609    60545   \n",
      "14     1669  3.8558  18.465  6.292  1.200  missing      142  missing       38   \n",
      "15     1583  3.0284  16.325  0.000  0.000  missing  missing  missing    51450   \n",
      "16     1899  0.0970   0.000  0.000  0.000     1015    13379    13379   246906   \n",
      "17     1690  8.7747  10.437  0.000  0.000      122      623      299     1140   \n",
      "18     1599  0.8601   1.525  1.525  0.000  missing      878  missing  missing   \n",
      "19     1859  0.0155   0.368  0.000  0.000      424    86509    12451    86635   \n",
      "20     1880  2.6101   0.000  0.000  0.000        0    19252     6342    59601   \n",
      "21     1852  3.6201   0.000  0.000  0.000      799    16515    16515   110651   \n",
      "22     1655  3.0268  14.748  0.000  0.000       48       48       48      198   \n",
      "23     1863  0.0401   0.000  0.000  0.000     1487     4955     4955    22902   \n",
      "24     1753  0.2251   0.000  0.000  0.000     1124     1124     1124        0   \n",
      "25     1894  0.0318   0.000  0.000  0.000     4655     7433     7433    25667   \n",
      "26     1803  0.3993   0.000  0.000  0.000      496    10505      496      991   \n",
      "27     1932  0.3276   0.000  0.000  0.000     6982    21569    18829   187209   \n",
      "28     1714  5.1904   0.770  0.000  0.000        0     1889      595    12574   \n",
      "29       na  2.0457   4.514  0.000  0.000  missing  missing  missing  missing   \n",
      "...     ...     ...     ...    ...    ...      ...      ...      ...      ...   \n",
      "79970  1834  1.2164   0.000  0.000  0.000     2212     5244     4203    16743   \n",
      "79971  1729  1.3696   0.000  0.000  0.000      356     4218     1982    18657   \n",
      "79972  1753  5.8283   0.000  0.000  0.000      180     4014      617     3667   \n",
      "79973  1748  1.9635   0.642  0.000  0.000      291     3469     3469    13131   \n",
      "79974  1771  1.7588   0.000  0.000  0.000       66    12626     6433    27946   \n",
      "79975  1766  0.9540   0.000  0.000  0.000     1140    10207    10207    55001   \n",
      "79976  1822  0.0000   1.853  1.853  0.000     2581    13361     5946    31018   \n",
      "79977  1824  0.5634   0.000  0.000  0.000     3964     4683     4683  missing   \n",
      "79978  1914  0.0544   0.000  0.000  0.000     3469    20424    20424    78774   \n",
      "79979  1600  2.6649  18.282  1.078  2.678        0     7205        0      956   \n",
      "79980  1822  0.5851   0.000  0.000  0.000        0    23685    23685   208174   \n",
      "79981  1693  0.1828  17.767  2.024  0.000      114    27514      384     2329   \n",
      "79982  1735  3.1701   0.260  0.000  0.000      117      892      117     3766   \n",
      "79983  1671  0.1380   0.000  0.000  0.000  missing      491  missing  missing   \n",
      "79984  1924  0.1221   0.000  0.000  0.000     2478   266683   266683   405300   \n",
      "79985  1670  0.0347   9.836  0.000  0.000      212     7848      491    29785   \n",
      "79986  1901  0.1782   0.000  0.000  0.000     4955    21753    12673    70293   \n",
      "79987  1835  0.5372   0.000  0.000  0.000        0    29723     3964    66770   \n",
      "79988  1927  0.0410   0.000  0.000  0.000    22000    30046    24165    75019   \n",
      "79989    na  0.1451   0.000  0.000  0.000  missing  missing  missing  missing   \n",
      "79990  1941  0.4834   0.000  0.000  0.000    10846    52806    35478   136461   \n",
      "79991  1899     NaN   0.000  0.000  0.000     7310    14519    14519     5252   \n",
      "79992  1761  2.0999   0.000  0.000  0.000       47    13477     1814     9320   \n",
      "79993  1700  0.3831   0.000  0.000  0.000      344      344      344      991   \n",
      "79994  1910  0.0000   0.000  0.000  0.000     4955    47306    47306    88124   \n",
      "79995  1736  2.1740   0.000  0.000  0.000       11     4248     1577    13379   \n",
      "79996  1724  0.0000   1.108  0.768  0.000  missing    64041  missing    10926   \n",
      "79997  1605  0.2901  11.561  0.937  2.976  missing     2277  missing     3964   \n",
      "79998  1780  1.1874   0.000  0.000  0.000        0     6356     4802     3206   \n",
      "79999  1727  1.9288   1.441  0.000  0.000        0    25773     2869   132985   \n",
      "\n",
      "        mvar10     ...     mvar39   mvar40   mvar41   mvar42 mvar43   mvar44  \\\n",
      "0        18414     ...          1    73.78   82.547  0.08696     10  0.63899   \n",
      "1        13664     ...          0   99.129  missing        0     13  0.63836   \n",
      "2         2536     ...          0  missing    29.29        0      1  1.00000   \n",
      "3        37013     ...          0   96.272  missing  0.15385      3  0.53241   \n",
      "4         4696     ...          0  115.019  missing        0      1  0.92665   \n",
      "5            0     ...         na  missing  missing      1.5      0      NaN   \n",
      "6         1498     ...          0   88.171  missing        0      2  0.87224   \n",
      "7      missing     ...         na  missing  missing  missing     na      NaN   \n",
      "8        65843     ...          0  missing  missing        0     10  0.89868   \n",
      "9        31640     ...          0  missing    45.59  0.08824     14  0.33834   \n",
      "10      110271     ...          0  missing  missing        0     17  0.80620   \n",
      "11        7086     ...          1  missing  missing  0.61111      7  0.81172   \n",
      "12        6612     ...          0  missing  missing        0      5  0.98031   \n",
      "13       24893     ...          0  missing  missing        0     13  0.35724   \n",
      "14         142     ...          0  107.825   98.664     0.56     11  0.29169   \n",
      "15           0     ...          0  missing  missing  0.32353      2      NaN   \n",
      "16       56533     ...          0   10.384  missing        0     19  0.47480   \n",
      "17        2043     ...          0  missing  missing  0.63636      5  0.94951   \n",
      "18         878     ...          1  missing   91.175      0.8      0  1.00000   \n",
      "19      142081     ...          0  missing  missing        0     12  0.34730   \n",
      "20       86906     ...          0  missing   72.497        0     14  0.28708   \n",
      "21       41311     ...          0  missing  missing        0     13  0.75349   \n",
      "22          48     ...          0  missing  missing        1      1  1.00000   \n",
      "23       21772     ...          0   96.895  missing        0     12  0.40853   \n",
      "24        1124     ...          0  missing  missing  missing      0  1.00000   \n",
      "25       12345     ...          0  missing        0        0      3  0.99419   \n",
      "26       18163     ...          0   91.752   87.306      0.2      5  0.75289   \n",
      "27      113813     ...          0  missing  missing        0     11  0.99710   \n",
      "28        4825     ...          0  missing  missing  0.35714      6  0.85082   \n",
      "29           0     ...         na  missing  missing  1.16667      0      NaN   \n",
      "...        ...     ...        ...      ...      ...      ...    ...      ...   \n",
      "79970    13831     ...          0  missing   97.398        0      8  0.58040   \n",
      "79971     8921     ...          0  missing   83.663  0.09091      6  0.62632   \n",
      "79972     9786     ...          0  missing   87.094  0.11111      9  0.59364   \n",
      "79973    14393     ...          0  missing   92.244     0.44     14  0.83809   \n",
      "79974    24401     ...          0  missing   40.477        0     10  0.46863   \n",
      "79975    20636     ...          0  missing  missing     0.05     14  0.54754   \n",
      "79976    76774     ...          0   73.611   44.656  0.03448     20  0.23177   \n",
      "79977     8647     ...          0  missing  missing  missing     na  0.67222   \n",
      "79978    27856     ...          0  missing  missing        0      8  1.00000   \n",
      "79979     7360     ...          1  132.335   56.867  0.55263     14  0.11763   \n",
      "79980    55719     ...          0  missing  missing        0     17  0.81438   \n",
      "79981    48080     ...          0   74.814  missing  0.17857      5  0.53340   \n",
      "79982     1265     ...          0  missing   99.026        0      2  0.96747   \n",
      "79983      491     ...          0  missing  missing      0.8      2  1.00000   \n",
      "79984   390558     ...          0  missing   70.799        0     13  0.75322   \n",
      "79985    16226     ...          0  missing     78.7  0.13636     10  0.85771   \n",
      "79986    62980     ...          0  missing   61.301        0     10  0.86356   \n",
      "79987    85900     ...          0  missing  missing        0      9  0.41685   \n",
      "79988    88343     ...          0  missing   19.444        0      7  0.53750   \n",
      "79989        0     ...         na  missing  missing      1.5      0      NaN   \n",
      "79990   176240     ...          0  missing  missing  0.05882      8  0.84170   \n",
      "79991     4949     ...          0  missing  missing        0      3  0.44615   \n",
      "79992     2500     ...          0  missing  missing    0.125      5  0.73640   \n",
      "79993      344     ...          0  missing  missing  0.66667      2  0.97374   \n",
      "79994   107148     ...          0  missing  missing        0      4  0.79867   \n",
      "79995     6671     ...          0  missing   78.378        0      4  0.43829   \n",
      "79996    84839     ...          0  missing   38.325  0.16667     14  0.57931   \n",
      "79997     5709     ...          2   101.85   93.142      0.5      4  0.42069   \n",
      "79998    18180     ...          0  missing   77.022  0.06061      9  0.53251   \n",
      "79999    71788     ...          0     32.4  missing  0.07143     12  0.68482   \n",
      "\n",
      "      mvar45 mvar46 mvar47 default_ind  \n",
      "0         na      0      C           0  \n",
      "1         na     na      L           1  \n",
      "2         na      0      C           1  \n",
      "3          0      0      L           0  \n",
      "4         na     na      L           0  \n",
      "5         na     na      C           1  \n",
      "6         na      0      C           1  \n",
      "7         na     na      C           0  \n",
      "8          0      0      L           0  \n",
      "9         na      0      L           0  \n",
      "10         0      0      L           0  \n",
      "11         0      0      C           0  \n",
      "12        na     na      C           0  \n",
      "13        na      0      C           0  \n",
      "14        na      1      C           0  \n",
      "15         0     na      C           0  \n",
      "16         0      0      L           0  \n",
      "17        na      0      L           0  \n",
      "18        na      0      C           1  \n",
      "19         0      0      L           0  \n",
      "20        na      0      L           0  \n",
      "21        na     na      L           0  \n",
      "22        na     na      C           1  \n",
      "23        na      0      L           0  \n",
      "24        na     na      C           1  \n",
      "25         0      0      L           0  \n",
      "26         0      0      L           0  \n",
      "27         0      0      C           0  \n",
      "28         0      0      L           0  \n",
      "29        na     na      L           0  \n",
      "...      ...    ...    ...         ...  \n",
      "79970     na      0      C           0  \n",
      "79971      0      0      C           0  \n",
      "79972     na      0      L           0  \n",
      "79973      0      0      L           0  \n",
      "79974     na      0      C           0  \n",
      "79975     na     na      C           0  \n",
      "79976     na      0      C           0  \n",
      "79977     na     na      C           0  \n",
      "79978      0      0      L           0  \n",
      "79979     na      0      L           1  \n",
      "79980      0     na      L           0  \n",
      "79981     na      0      C           0  \n",
      "79982     na      0      C           1  \n",
      "79983     na     na      C           0  \n",
      "79984      0      0      L           0  \n",
      "79985     na      0      L           0  \n",
      "79986      0      0      L           0  \n",
      "79987      0      0      L           0  \n",
      "79988      0      0      L           0  \n",
      "79989     na     na      L           0  \n",
      "79990      0      0      L           0  \n",
      "79991     na     na      L           0  \n",
      "79992      0      0      C           1  \n",
      "79993      0      0      C           1  \n",
      "79994     na     na      L           0  \n",
      "79995     na      0      C           0  \n",
      "79996      0      0      C           0  \n",
      "79997     na      0      C           1  \n",
      "79998     na      0      L           0  \n",
      "79999      0      0      C           1  \n",
      "\n",
      "[80000 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "#replace all missing values with mean of existing values in training set\n",
    "#same can be done for testing set but data leakage can occur\n",
    "df_training = df_training.replace('missing', df_training.mean(axis = 0))\n",
    "df_training = df_training.replace('na', df_training.mean(axis = 0))\n",
    "df_training = df_training.replace('N/A',df_training.mean(axis = 0))\n",
    "#df_training.fillna(df_training.mean(axis = 0))\n",
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people: 80000\n",
      "Number of features: 47\n"
     ]
    }
   ],
   "source": [
    "#general informations\n",
    "\n",
    "n_people = df_training.shape[0]\n",
    "n_features = df_training.shape[1]-1\n",
    "print(\"Total number of people: {}\".format(n_people))\n",
    "print(\"Number of features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46', 'mvar47']\n",
      "Target column: default_ind\n",
      "\n",
      "Feature values:-\n",
      "  mvar1   mvar2  mvar3  mvar4  mvar5    mvar6  mvar7    mvar8    mvar9 mvar10  \\\n",
      "0  1696  1.6541  0.000    0.0    0.0        0   6015      322    40369  18414   \n",
      "1  1846  0.8095  0.000    0.0    0.0      102   7532     3171    18234  13664   \n",
      "2  1745  0.4001  0.000    0.0    0.0  missing   2536  missing  missing   2536   \n",
      "3  1739  0.2193  0.000    0.0    0.0     1982  26440     4955    20316  37013   \n",
      "4  1787  0.0118  0.225    0.0    0.0     5451   5494     5494     7987   4696   \n",
      "\n",
      "   ...   mvar38 mvar39   mvar40   mvar41   mvar42 mvar43   mvar44 mvar45  \\\n",
      "0  ...        4      1    73.78   82.547  0.08696     10  0.63899     na   \n",
      "1  ...        2      0   99.129  missing        0     13  0.63836     na   \n",
      "2  ...        1      0  missing    29.29        0      1  1.00000     na   \n",
      "3  ...        2      0   96.272  missing  0.15385      3  0.53241      0   \n",
      "4  ...        2      0  115.019  missing        0      1  0.92665     na   \n",
      "\n",
      "  mvar46 mvar47  \n",
      "0      0      C  \n",
      "1     na      L  \n",
      "2      0      C  \n",
      "3      0      L  \n",
      "4     na      L  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "#preparing data\n",
    "\n",
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(df_training.columns[:-1])  # all columns but last are features\n",
    "target_col = df_training.columns[-1]  # last column is the target/label\n",
    "print(\"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print( \"Target column: {}\".format(target_col))\n",
    "\n",
    "X_all = df_training[feature_cols]  # feature values for all people\n",
    "y_all = df_training[target_col]  # corresponding targets/labels\n",
    "print (\"\\nFeature values:-\")\n",
    "print(X_all.head())  # print the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['C', 'L'], [1, 0])\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect columns in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing number of training and test samples\n",
    "num_all = df_training.shape[0]  # same as len(df_training)\n",
    "num_train = 0.9 * num_all # about 90% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_all, y_all, test_size=num_test)\n",
    "print(\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print( \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print (\"F1 score for training set: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "\n",
    "#Now just by changing the classifier we can compare the f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "train_predict(clf, X_train.sample(n=200, random_state=200), y_train.sample(n=200, random_state=200), X_test, y_test)\n",
    "train_predict(clf, X_train.sample(n=100, random_state=100), y_train.sample(n=100, random_state=100), X_test, y_test)\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "mnb = naive_bayes.MultinomialNB()\n",
    "train_predict(mnb, X_train, y_train, X_test, y_test)\n",
    "train_predict(mnb, X_train.sample(n=200, random_state=201), y_train.sample(n=200, random_state=201), X_test, y_test)\n",
    "train_predict(mnb, X_train.sample(n=100, random_state=101), y_train.sample(n=100, random_state=101), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "train_predict(dtc, X_train, y_train, X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=200, random_state=202), y_train.sample(n=200, random_state=202), X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=100, random_state=102), y_train.sample(n=100, random_state=102), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the best model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {'max_depth': (1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 'n_estimators': (100, 125, 150, 500)}\n",
    "sss = cross_validation.StratifiedShuffleSplit(y_train, test_size=num_test)\n",
    "gs = GridSearchCV(estimator=clf, n_jobs=-1, scoring=make_scorer(f1_score, pos_label='yes'), param_grid=parameters,\n",
    "                  cv=sss)\n",
    "gs.fit(X_train, y_train)\n",
    "best_estimator = gs.best_estimator_\n",
    "print(\"best estimator:\\n{}\".format(best_estimator))\n",
    "print ('')\n",
    "print(\"best parameter:\\n{}\".format(gs.best_params_))\n",
    "print('')\n",
    "print(\"F1 score:\\n{}\".format(f1_score(y_test, best_estimator.predict(X_test), pos_label='yes')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
