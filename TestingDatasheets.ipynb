{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#Reading data\n",
    "\n",
    "df_training = pd.read_csv(\"Training_dataset_Original.csv\")\n",
    "df_eval = pd.read_csv(\"Evaluation_dataset.csv\")\n",
    "df_leader = pd.read_csv(\"Leaderboard_dataset.csv\")\n",
    "df_datadict = pd.read_csv(\"Data_Dictionary.csv\")\n",
    "\n",
    "print(\"data reading complete\")\n",
    "\n",
    "df_training = df_training.drop(['application_key'],axis=1)\n",
    "application_key = df_leader.loc[:, 'application_key']\n",
    "\n",
    "df_leader = df_leader.drop(['application_key'],axis=1)\n",
    "\n",
    "print(\"data application_key dropped\")\n",
    "\n",
    "mvar47 = df_training.loc[:, 'mvar47']\n",
    "mvar47leader = df_leader.loc[:, 'mvar47']\n",
    "\n",
    "df_training = df_training.drop(['mvar47'],axis=1)\n",
    "df_leader = df_leader.drop(['mvar47'],axis=1)\n",
    "\n",
    "print(\"data mvar47 dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed\n",
      "      mvar1   mvar2   mvar3  mvar4  mvar5  mvar6   mvar7   mvar8   mvar9  \\\n",
      "0      1696  1.6541   0.000  0.000  0.000      0    6015     322   40369   \n",
      "1      1846  0.8095   0.000  0.000  0.000    102    7532    3171   18234   \n",
      "2      1745  0.4001   0.000  0.000  0.000      0    2536       0       0   \n",
      "3      1739  0.2193   0.000  0.000  0.000   1982   26440    4955   20316   \n",
      "4      1787  0.0118   0.225  0.000  0.000   5451    5494    5494    7987   \n",
      "5      1579  0.0000   3.502  0.000  0.000      0       0       0       0   \n",
      "6      1818  0.4001   0.000  0.000  0.000      0    1088       0    1536   \n",
      "7         0  0.0000   0.000  0.000  0.000      0       0       0       0   \n",
      "8      1836  0.1358   0.000  0.000  0.000    347   38964   17828   70729   \n",
      "9      1839  0.1981   0.000  0.000  0.000    793    6131    6045   48959   \n",
      "10     1903  0.0000   0.000  0.000  0.000     22   19518    9910   90618   \n",
      "11     1681  1.5888   5.685  3.566  0.000     93    3554     439    2527   \n",
      "12     1841  0.5388   0.000  0.000  0.000   1487   19449   19449    6739   \n",
      "13     1794  1.9684   0.000  0.000  0.000    856    8609    8609   60545   \n",
      "14     1669  3.8558  18.465  6.292  1.200      0     142       0      38   \n",
      "15     1583  3.0284  16.325  0.000  0.000      0       0       0   51450   \n",
      "16     1899  0.0970   0.000  0.000  0.000   1015   13379   13379  246906   \n",
      "17     1690  8.7747  10.437  0.000  0.000    122     623     299    1140   \n",
      "18     1599  0.8601   1.525  1.525  0.000      0     878       0       0   \n",
      "19     1859  0.0155   0.368  0.000  0.000    424   86509   12451   86635   \n",
      "20     1880  2.6101   0.000  0.000  0.000      0   19252    6342   59601   \n",
      "21     1852  3.6201   0.000  0.000  0.000    799   16515   16515  110651   \n",
      "22     1655  3.0268  14.748  0.000  0.000     48      48      48     198   \n",
      "23     1863  0.0401   0.000  0.000  0.000   1487    4955    4955   22902   \n",
      "24     1753  0.2251   0.000  0.000  0.000   1124    1124    1124       0   \n",
      "25     1894  0.0318   0.000  0.000  0.000   4655    7433    7433   25667   \n",
      "26     1803  0.3993   0.000  0.000  0.000    496   10505     496     991   \n",
      "27     1932  0.3276   0.000  0.000  0.000   6982   21569   18829  187209   \n",
      "28     1714  5.1904   0.770  0.000  0.000      0    1889     595   12574   \n",
      "29        0  2.0457   4.514  0.000  0.000      0       0       0       0   \n",
      "...     ...     ...     ...    ...    ...    ...     ...     ...     ...   \n",
      "79970  1834  1.2164   0.000  0.000  0.000   2212    5244    4203   16743   \n",
      "79971  1729  1.3696   0.000  0.000  0.000    356    4218    1982   18657   \n",
      "79972  1753  5.8283   0.000  0.000  0.000    180    4014     617    3667   \n",
      "79973  1748  1.9635   0.642  0.000  0.000    291    3469    3469   13131   \n",
      "79974  1771  1.7588   0.000  0.000  0.000     66   12626    6433   27946   \n",
      "79975  1766  0.9540   0.000  0.000  0.000   1140   10207   10207   55001   \n",
      "79976  1822  0.0000   1.853  1.853  0.000   2581   13361    5946   31018   \n",
      "79977  1824  0.5634   0.000  0.000  0.000   3964    4683    4683       0   \n",
      "79978  1914  0.0544   0.000  0.000  0.000   3469   20424   20424   78774   \n",
      "79979  1600  2.6649  18.282  1.078  2.678      0    7205       0     956   \n",
      "79980  1822  0.5851   0.000  0.000  0.000      0   23685   23685  208174   \n",
      "79981  1693  0.1828  17.767  2.024  0.000    114   27514     384    2329   \n",
      "79982  1735  3.1701   0.260  0.000  0.000    117     892     117    3766   \n",
      "79983  1671  0.1380   0.000  0.000  0.000      0     491       0       0   \n",
      "79984  1924  0.1221   0.000  0.000  0.000   2478  266683  266683  405300   \n",
      "79985  1670  0.0347   9.836  0.000  0.000    212    7848     491   29785   \n",
      "79986  1901  0.1782   0.000  0.000  0.000   4955   21753   12673   70293   \n",
      "79987  1835  0.5372   0.000  0.000  0.000      0   29723    3964   66770   \n",
      "79988  1927  0.0410   0.000  0.000  0.000  22000   30046   24165   75019   \n",
      "79989     0  0.1451   0.000  0.000  0.000      0       0       0       0   \n",
      "79990  1941  0.4834   0.000  0.000  0.000  10846   52806   35478  136461   \n",
      "79991  1899  0.0000   0.000  0.000  0.000   7310   14519   14519    5252   \n",
      "79992  1761  2.0999   0.000  0.000  0.000     47   13477    1814    9320   \n",
      "79993  1700  0.3831   0.000  0.000  0.000    344     344     344     991   \n",
      "79994  1910  0.0000   0.000  0.000  0.000   4955   47306   47306   88124   \n",
      "79995  1736  2.1740   0.000  0.000  0.000     11    4248    1577   13379   \n",
      "79996  1724  0.0000   1.108  0.768  0.000      0   64041       0   10926   \n",
      "79997  1605  0.2901  11.561  0.937  2.976      0    2277       0    3964   \n",
      "79998  1780  1.1874   0.000  0.000  0.000      0    6356    4802    3206   \n",
      "79999  1727  1.9288   1.441  0.000  0.000      0   25773    2869  132985   \n",
      "\n",
      "       mvar10     ...     mvar38 mvar39   mvar40  mvar41   mvar42 mvar43  \\\n",
      "0       18414     ...          4      1    73.78  82.547  0.08696     10   \n",
      "1       13664     ...          2      0   99.129       0        0     13   \n",
      "2        2536     ...          1      0        0   29.29        0      1   \n",
      "3       37013     ...          2      0   96.272       0  0.15385      3   \n",
      "4        4696     ...          2      0  115.019       0        0      1   \n",
      "5           0     ...          2      0        0       0      1.5      0   \n",
      "6        1498     ...          0      0   88.171       0        0      2   \n",
      "7           0     ...          0      0        0       0        0      0   \n",
      "8       65843     ...          2      0        0       0        0     10   \n",
      "9       31640     ...          0      0        0   45.59  0.08824     14   \n",
      "10     110271     ...          2      0        0       0        0     17   \n",
      "11       7086     ...          5      1        0       0  0.61111      7   \n",
      "12       6612     ...          6      0        0       0        0      5   \n",
      "13      24893     ...          1      0        0       0        0     13   \n",
      "14        142     ...         15      0  107.825  98.664     0.56     11   \n",
      "15          0     ...          4      0        0       0  0.32353      2   \n",
      "16      56533     ...          2      0   10.384       0        0     19   \n",
      "17       2043     ...         12      0        0       0  0.63636      5   \n",
      "18        878     ...          1      1        0  91.175      0.8      0   \n",
      "19     142081     ...          2      0        0       0        0     12   \n",
      "20      86906     ...         14      0        0  72.497        0     14   \n",
      "21      41311     ...          2      0        0       0        0     13   \n",
      "22         48     ...          4      0        0       0        1      1   \n",
      "23      21772     ...          4      0   96.895       0        0     12   \n",
      "24       1124     ...          1      0        0       0        0      0   \n",
      "25      12345     ...          1      0        0       0        0      3   \n",
      "26      18163     ...          1      0   91.752  87.306      0.2      5   \n",
      "27     113813     ...          2      0        0       0        0     11   \n",
      "28       4825     ...          8      0        0       0  0.35714      6   \n",
      "29          0     ...          4      0        0       0  1.16667      0   \n",
      "...       ...     ...        ...    ...      ...     ...      ...    ...   \n",
      "79970   13831     ...          8      0        0  97.398        0      8   \n",
      "79971    8921     ...          7      0        0  83.663  0.09091      6   \n",
      "79972    9786     ...         10      0        0  87.094  0.11111      9   \n",
      "79973   14393     ...         12      0        0  92.244     0.44     14   \n",
      "79974   24401     ...          4      0        0  40.477        0     10   \n",
      "79975   20636     ...         13      0        0       0     0.05     14   \n",
      "79976   76774     ...          4      0   73.611  44.656  0.03448     20   \n",
      "79977    8647     ...          2      0        0       0        0      0   \n",
      "79978   27856     ...          1      0        0       0        0      8   \n",
      "79979    7360     ...          9      1  132.335  56.867  0.55263     14   \n",
      "79980   55719     ...          3      0        0       0        0     17   \n",
      "79981   48080     ...          4      0   74.814       0  0.17857      5   \n",
      "79982    1265     ...          3      0        0  99.026        0      2   \n",
      "79983     491     ...          1      0        0       0      0.8      2   \n",
      "79984  390558     ...          4      0        0  70.799        0     13   \n",
      "79985   16226     ...          5      0        0    78.7  0.13636     10   \n",
      "79986   62980     ...          5      0        0  61.301        0     10   \n",
      "79987   85900     ...          3      0        0       0        0      9   \n",
      "79988   88343     ...          3      0        0  19.444        0      7   \n",
      "79989       0     ...          1      0        0       0      1.5      0   \n",
      "79990  176240     ...          1      0        0       0  0.05882      8   \n",
      "79991    4949     ...          1      0        0       0        0      3   \n",
      "79992    2500     ...          5      0        0       0    0.125      5   \n",
      "79993     344     ...          3      0        0       0  0.66667      2   \n",
      "79994  107148     ...          2      0        0       0        0      4   \n",
      "79995    6671     ...          4      0        0  78.378        0      4   \n",
      "79996   84839     ...          5      0        0  38.325  0.16667     14   \n",
      "79997    5709     ...          5      2   101.85  93.142      0.5      4   \n",
      "79998   18180     ...          8      0        0  77.022  0.06061      9   \n",
      "79999   71788     ...          4      0     32.4       0  0.07143     12   \n",
      "\n",
      "        mvar44 mvar45 mvar46 default_ind  \n",
      "0      0.63899      0      0           0  \n",
      "1      0.63836      0      0           1  \n",
      "2      1.00000      0      0           1  \n",
      "3      0.53241      0      0           0  \n",
      "4      0.92665      0      0           0  \n",
      "5      0.00000      0      0           1  \n",
      "6      0.87224      0      0           1  \n",
      "7      0.00000      0      0           0  \n",
      "8      0.89868      0      0           0  \n",
      "9      0.33834      0      0           0  \n",
      "10     0.80620      0      0           0  \n",
      "11     0.81172      0      0           0  \n",
      "12     0.98031      0      0           0  \n",
      "13     0.35724      0      0           0  \n",
      "14     0.29169      0      1           0  \n",
      "15     0.00000      0      0           0  \n",
      "16     0.47480      0      0           0  \n",
      "17     0.94951      0      0           0  \n",
      "18     1.00000      0      0           1  \n",
      "19     0.34730      0      0           0  \n",
      "20     0.28708      0      0           0  \n",
      "21     0.75349      0      0           0  \n",
      "22     1.00000      0      0           1  \n",
      "23     0.40853      0      0           0  \n",
      "24     1.00000      0      0           1  \n",
      "25     0.99419      0      0           0  \n",
      "26     0.75289      0      0           0  \n",
      "27     0.99710      0      0           0  \n",
      "28     0.85082      0      0           0  \n",
      "29     0.00000      0      0           0  \n",
      "...        ...    ...    ...         ...  \n",
      "79970  0.58040      0      0           0  \n",
      "79971  0.62632      0      0           0  \n",
      "79972  0.59364      0      0           0  \n",
      "79973  0.83809      0      0           0  \n",
      "79974  0.46863      0      0           0  \n",
      "79975  0.54754      0      0           0  \n",
      "79976  0.23177      0      0           0  \n",
      "79977  0.67222      0      0           0  \n",
      "79978  1.00000      0      0           0  \n",
      "79979  0.11763      0      0           1  \n",
      "79980  0.81438      0      0           0  \n",
      "79981  0.53340      0      0           0  \n",
      "79982  0.96747      0      0           1  \n",
      "79983  1.00000      0      0           0  \n",
      "79984  0.75322      0      0           0  \n",
      "79985  0.85771      0      0           0  \n",
      "79986  0.86356      0      0           0  \n",
      "79987  0.41685      0      0           0  \n",
      "79988  0.53750      0      0           0  \n",
      "79989  0.00000      0      0           0  \n",
      "79990  0.84170      0      0           0  \n",
      "79991  0.44615      0      0           0  \n",
      "79992  0.73640      0      0           1  \n",
      "79993  0.97374      0      0           1  \n",
      "79994  0.79867      0      0           0  \n",
      "79995  0.43829      0      0           0  \n",
      "79996  0.57931      0      0           0  \n",
      "79997  0.42069      0      0           1  \n",
      "79998  0.53251      0      0           0  \n",
      "79999  0.68482      0      0           1  \n",
      "\n",
      "[80000 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "#replace all missing values with mean of existing values in training set\n",
    "#same can be done for testing set but data leakage can occur\n",
    "\n",
    "df_training = df_training.replace('missing', np.nan)\n",
    "df_training = df_training.replace('na', np.nan)\n",
    "df_training = df_training.replace('N/A', np.nan)\n",
    "\n",
    "df_training = df_training.fillna(0)\n",
    "\n",
    "df_leader = df_leader.replace('missing', np.nan)\n",
    "df_leader = df_leader.replace('na', np.nan)\n",
    "df_leader = df_leader.replace('N/A', np.nan)\n",
    "\n",
    "df_leader = df_leader.fillna(0)\n",
    "\n",
    "print(\"data processed\")\n",
    "\n",
    "#df_training = (df_training - df_training.mean()) / (df_training.max() - df_training.min())\n",
    "#for head in df_training:\n",
    "    #df_training[head] = np.sqrt(df_training[head])\n",
    "\n",
    "#print(\"data normalised\")\n",
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people: 80000\n",
      "Number of features: 46\n"
     ]
    }
   ],
   "source": [
    "#general informations\n",
    "\n",
    "n_people = df_training.shape[0]\n",
    "n_features = df_training.shape[1]-1\n",
    "print(\"Total number of people: {}\".format(n_people))\n",
    "print(\"Number of features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46']\n",
      "Target column: default_ind\n",
      "\n",
      "Feature values:-\n",
      "  mvar1   mvar2  mvar3  mvar4  mvar5 mvar6  mvar7 mvar8  mvar9 mvar10  ...    \\\n",
      "0  1696  1.6541  0.000    0.0    0.0     0   6015   322  40369  18414  ...     \n",
      "1  1846  0.8095  0.000    0.0    0.0   102   7532  3171  18234  13664  ...     \n",
      "2  1745  0.4001  0.000    0.0    0.0     0   2536     0      0   2536  ...     \n",
      "3  1739  0.2193  0.000    0.0    0.0  1982  26440  4955  20316  37013  ...     \n",
      "4  1787  0.0118  0.225    0.0    0.0  5451   5494  5494   7987   4696  ...     \n",
      "\n",
      "  mvar37 mvar38 mvar39   mvar40  mvar41   mvar42 mvar43   mvar44 mvar45 mvar46  \n",
      "0     10      4      1    73.78  82.547  0.08696     10  0.63899      0      0  \n",
      "1      0      2      0   99.129       0        0     13  0.63836      0      0  \n",
      "2      0      1      0        0   29.29        0      1  1.00000      0      0  \n",
      "3      3      2      0   96.272       0  0.15385      3  0.53241      0      0  \n",
      "4      3      2      0  115.019       0        0      1  0.92665      0      0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data normalised\n"
     ]
    }
   ],
   "source": [
    "#preparing data\n",
    "\n",
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(df_training.columns[:-1])  # all columns but last are features\n",
    "target_col = df_training.columns[-1] # last column is the target/label\n",
    "print(\"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print( \"Target column: {}\".format(target_col))\n",
    "\n",
    "feature_cols_leader = list(df_leader.columns[:])  # all columns but last are features\n",
    "\n",
    "X_all = df_training[feature_cols]  # feature values for all people\n",
    "y_all = df_training[target_col]  # corresponding targets/labels\n",
    "\n",
    "X_leader = df_leader[feature_cols_leader]\n",
    "\n",
    "print (\"\\nFeature values:-\")\n",
    "print(X_all.head())  # print the first 5 rows\n",
    "\n",
    "X_all = X_all.convert_objects(convert_numeric=True)\n",
    "X_leader = X_leader.convert_objects(convert_numeric=True)\n",
    "\n",
    "\n",
    "for head in X_all:\n",
    "    series = X_all[head]\n",
    "    mean = series.mean()\n",
    "    maximum = series.max()\n",
    "    minimum = series.min()\n",
    "    series = (series - minimum)/(maximum - minimum)\n",
    "    X_all[head] = series\n",
    "    \n",
    "for head in X_leader:\n",
    "    series = X_leader[head]\n",
    "    mean = series.mean()\n",
    "    maximum = series.max()\n",
    "    minimum = series.min()\n",
    "    series = (series - minimum)/(maximum - minimum)\n",
    "    X_leader[head] = series\n",
    "    \n",
    "\n",
    "print(\"data normalised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (47):-\n",
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46', 'mvar47']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['C', 'L'], [1, 0])\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        #if col_data.dtype == object:\n",
    "            #col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect columns in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "X_leader = preprocess_features(X_leader)\n",
    "mvar47 = mvar47.replace('C',0)\n",
    "mvar47 = mvar47.replace('L',1)\n",
    "mvar47leader = mvar47leader.replace('C',0)\n",
    "mvar47leader = mvar47leader.replace('L',1)\n",
    "\n",
    "X_all = pd.concat((X_all,mvar47),axis =1)\n",
    "X_leader = pd.concat((X_leader,mvar47leader),axis =1)\n",
    "\n",
    "print(\"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 72000 samples\n",
      "Test set: 8000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# preparing number of training and test samples\n",
    "num_all = df_training.shape[0]  # same as len(df_training)\n",
    "num_train = 72000 # about 90% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_all, y_all, test_size=num_test)\n",
    "print(\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 2.452\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "#clf = SVC(gamma='auto')\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.243\n",
      "F1 score for training set: 0.9682392488698273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print( \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label=1)\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print (\"F1 score for training set: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.038\n",
      "F1 score for test set: 0.4735303670022734\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "\n",
    "#Now just by changing the classifier we can compare the f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.023\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for training set: 0.9565217391304348\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.3440559440559441\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.016\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for test set: 0.4370651486401012\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Training set size: {}\".format(len(X_train)))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print( \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "train_predict(clf, X_train.sample(n=200, random_state=200), y_train.sample(n=200, random_state=200), X_test, y_test)\n",
    "train_predict(clf, X_train.sample(n=100, random_state=100), y_train.sample(n=100, random_state=100), X_test, y_test)\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 72000\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 2.868\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.031\n",
      "F1 score for training set: 0.9999436587976788\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.4649761486316846\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.016\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.4490285440153514\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for test set: 0.35917114351496543\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "train_predict(dtc, X_train, y_train, X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=200, random_state=202), y_train.sample(n=200, random_state=202), X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=100, random_state=102), y_train.sample(n=100, random_state=102), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#choosing the best model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {'max_depth': (1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 'n_estimators': (100, 125, 150, 500)}\n",
    "sss = cross_validation.StratifiedShuffleSplit(y_train, test_size=num_test)\n",
    "gs = GridSearchCV(estimator=clf, n_jobs=-1, scoring=make_scorer(f1_score, pos_label=1), param_grid=parameters,\n",
    "                  cv=sss)\n",
    "gs.fit(X_train, y_train)\n",
    "best_estimator = gs.best_estimator_\n",
    "print(\"best estimator:\\n{}\".format(best_estimator))\n",
    "print ('')\n",
    "print(\"best parameter:\\n{}\".format(gs.best_params_))\n",
    "print('')\n",
    "print(\"F1 score:\\n{}\".format(f1_score(y_test, best_estimator.predict(X_test), pos_label=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
